---
layout: post
title: Infinite Monkey Theorem and the Borel-Cantelli Lemmas
date: 2019-02-11 00:33
author: baruuum
comments: true
categories: [Borel-Cantelli Lemma, Monkeys, Infinite Monkey Theorem, Math, Probability]
---
After submitting another two fellowship applications to survive the next year, I was relaxing a little bit by randomly searching the web, when I came across this thing called the "infinite monkey theorem.'' The theorem says that if and infinite number of monkeys randomly punch on a typewriter, the probability that one of them will write Hamlet (or all of Shakespeare's work) is equal to one. There are in fact many versions of this theorem, and I'm not sure which one is the real thing, but we'll see that not only one monkey but an infinite number of monkeys will write Hamlet with probability equal to one.

The theorem is quite amusing not only because of the imagine of a monkey punching on a typewriter but also because it highlights a counter-intuitive result that arises from  dealing with infinite things. After all, it seems plausible that one monkey would eventually succeed, but an infinite number of monkeys succeeding is a different story.


The statement itself is a straightforward corollary of the second Borel-Cantelli Lemma. And, fortunately, I had written a note on the lemma in the past. I recall starting to write it when I had difficulties with understanding limit suprema/infima of sequences of sets. This was when I was reading my very first textbook in mathematical statistics (I think I have chosen the wrong book back then...). Afterwards, the note was updated several times, as new theorems related to limit suprema and infima of sets were encountered. So, here is an edited version of the note, with an extra section on the infinite monkey theorem at the end.




<h3> Suprema and Infima </h3>


Let us start with the definition of supremum, $\sup$, and infimum, $\inf$. Consider a partially ordered set $(\Omega, \le)$ and let $A \subset \Omega$ be a subset that is bounded from above. For example, the real line is a partially ordered set, often called **poset**, with respect to the relation "$\le$.'' An upper bound of $A$ is an element $u\in \Omega$ such that $a \le u$ for all $a\in A$. Further, given a set $U\_A$ of upper bounds of $A$, the **supremum** or the **least upper bound** of $A$, denoted by $\sup A$, is the element $\bar u \in U\_A$ such that $\bar u \le u$ for all $u\in U\_A$. The **infimum** or the **greatest lower bound** is analogously defined as the element $\bar l\in \Omega$ that satisfies $\bar l \ge l$ for all $l \in L\_A$, where $L\_A$ is the set of all lower bounds of $A$.


Can we not simply use the maximum of the set $A$ rather than thinking in terms of suprema? The problem is that, often, the maximum of a set does not exist. A simple example is the open interval $A = \\{a \in \mathbb R \, \vert \, x < a < y\\}$. For every number $a \in A$, we can always find another number $a' = (y + a)/2$ that is an element of $A$ but is greater than $a$. Thus, there is no largest number in $A$. On the other hand, the least upper bound is well-defined and is equal to $y$. On the other hand, the least upper bound is well-defined and is equal to $y$.(It turns out that every bounded subset $A$ of real numbers has an infimum and supremum, which is quite an important result in mathematical analysis.)


<h3> Limit Superior and Limit Inferior of sequences in $\mathbb R$ </h3>


We can think also of suprema and infima of sequences of real numbers. Let $\\{x\_n\\}\_{n=1}^\infty$ be a bounded sequence in $\mathbb R$. Then the **limit superior** and **limit inferior** of the sequence is defined as

$$\limsup_{n\rightarrow \infty} x_n  = \lim_{n\rightarrow\infty} \left(\sup_{k\ge n} x_k\right)\qquad \text{ and } \qquad \liminf_{n\rightarrow \infty} = \lim_{n\rightarrow\infty}\left(\inf_{k\ge n}x_k\right).$$

To see what these expressions mean, pick any $n \ge 1$ and think of the *tail* of that sequence, $A\_n = \\{x\_n, x\_{n+1},...\\}$. For every $n' > n$, we have

$$ A_{n'} = \{x_{n'}, x_{n'+1},...\} \subseteq \{x_n, x_{n+1},...,x_{n'},x_{n'+1},...\} = A_{n}.$$

As $A\_{n'}$ is a subset of $A\_n$ for $n'\ge n$, the least upper bound of $A\_{n'}$ cannot be greater than that of $A\_n$, i.e., $\sup A\_{n'} \le \sup A\_n$. Also, note that $\\{\sup A\_n\\}\_{n=1}^\infty$ is itself a sequence of real numbers, which is monotonically decreasing in $n$. Lastly, since all bounded monotonic sequences of real numbers have a finite limit, it follows that the limit of $\\{\sup A\_n\\}\_{n=1}^\infty$ exists and is finite. It is precisely this limit, i.e.,  $\lim\_{n\rightarrow\infty} \\{\sup A\_n\\}$, which is the limit superior of the sequence $\\{x\_n\\}\_{n=1}^\infty$. Intuitively speaking, the further we go down the tail of $\\{x\_n\\}$, the less elements the remaining tail has, and the least upper bound of the tail can only become smaller until it reaches a stable limit.




We might consider a quite trivial example, which, however, will be helpful in understanding what follows. Suppose that the sequence $\\{x\_n\\}$ does not converge to single real number, but that for all $n \ge N$ elements of the tail $A\_N = \\{x\_N, x\_{N+1}, ...\\}$ take on values  in $\\{0,1,2\\}$, e.g., $A\_N = \\{0,2,1,0,1,0,...\\}$. Notice that if there are *only a finite number* of $2$s in $A\_N$ but $0$s and $1$s appear infinitely many times, then the $\limsup$ of the sequence cannot be equal to $2$. To see this, let $k$ be the last occurrence of $2$ in $A\_N$. Then $\sup\_{n > k} x\_n \ne 2$, as there are no $2$s anymore. On the other hand, if $1$ appears an infinite number of times in the tail of the sequence, there is no natural number $k'$ after which $1$ does not appear anymore. Regardless of how large we choose $k'$, there exists a $k'' > k'$ such that $x\_{k''} = 1$. Thus even though 0 appears an infinite times in the tail sequence as well and the sequence does not reach a stable limit, for all $k>N$ we have, $\sup\_{n \ge k} x\_n = 1$ and thus $\limsup\_{n\rightarrow \infty} x\_n = 1$. In short, all upper bounds that serve only a finite number of times as the least upper bound of the tail sequences $\\{A\_n\\}$ are dropped out as $n$ increases.


<h3> Limit Superior and Limit Inferior of Sequences of Sets in General </h3>


Next, let $\Omega$ be a set and $\mathcal P(\Omega)$ its power set, i.e., the collection of all subsets of $\Omega$. We can construct a partial order on $\mathcal P(\Omega)$ by the relation of set inclusion. Similarly to real numbers where we write $a\le b$ to mean that $a$ is "smaller or equal'' to $b$, we take relation $\subseteq$ on the subsets of $\Omega$ and write $A\subseteq B$ if all elements in $A$ are also elements of $B$. So, if $A\subseteq B$, then $A$ is "smaller or equal'' to $B$. Notice that all subsets of $\Omega$ are bounded below by the empty set and from above by $\Omega$ with respect to $\subseteq$, as $\varnothing \subseteq A \subseteq \Omega$ for all $A\in \mathcal P(A)$.


Let $\\{X\_1,X\_2,...\\}$ be a sequence in $\mathcal P(\Omega)$, i.e., a sequence of subsets of $\Omega$. Then, the limit superior and inferior of the sequence are defined as

$$\limsup_{n\rightarrow \infty} X_n  = \bigcap_{n=1}^\infty\bigcup_{k=n}^\infty X_k \qquad \text{ and } \qquad \liminf_{n\rightarrow \infty} = \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty X_k.$$



Boom. These expressions were the reason why I started this note. They just didn't make any sense to me when I first encountered them.


To move on, we notice that $\limsup$ and $\liminf$ of sequence sets have a similar structure to that of real sequences. Using the $\limsup$ as the main example, we see that we are concerned with a tail sequences of the form $\\{X\_k\\}\_{k=n}^\infty$ for some $n$, and that we are taking the "limit,'' here the union or intersection, with respect to $n$. So, we would need to understand why the limit is expressed in terms of unions and intersections.


Consider $\bigcup\_{n=1}^\infty X\_n$. In terms of set inclusion, the "smallest'' set that contains all elements that are in at least one of the $X\_n$'s is, by definition, their union. Hence $\bigcup X\_n$ is the supremum of the sequence $\\{X\_n\\}$. It follows that $\bigcup\_{k=n}^\infty X\_k$ is the supremum of the tail sequence $\mathcal Y\_n = \\{X\_n, X\_{n+1},...\\}$. Similarly, the "largest'' set that is a subset of all $X\_n \in \mathcal Y\_n$ is the intersection $\bigcap\_{k=n}^\infty X\_n$, i.e., the infimum of the tail sequence.


Next, we have to think about limits of set sequences. To do so, it is convenient to think of increasing and decreasing sequences, where these terms are, again, defined with respect to set inclusion. A sequence $\\{X\_1,X\_2,...\\}$ is said to be **increasing** if $X\_k \subseteq X\_{k+1}$ for all $k$. Similarly, it is said to be **decreasing** if $X\_k \supseteq X\_{k+1}$. Suppose we have a finite sequence $\\{W\_k\\}\_{k=1}^n$. If this sequence is increasing, it follows that, for all $k\le n$, $W\_k$ is a subset of $W\_n$ and thus $\bigcup\_{k=1}^n W\_k =W\_n$. This leads to the definition of a limit as

$$\lim_{n\rightarrow\infty}W_n = \lim_{n\rightarrow\infty} \bigcup_{k=1}^n W_k = \bigcup_{k=1}^\infty W_k.$$

Hence, the limiting set contains all the elements in $\Omega$ that appear in at least one of the $W\_k$, which is the union $\bigcup\_k W\_k$.


On the other hand, for a finite decreasing sequence $\\{V\_k\\}\_{k=1}^n$, we have that all elements in $V\_n$ are also elements of $V\_k$ for all $k \le n$. Thus $\bigcap\_{k=1}^n V\_k = V\_n$ and we can define

$$\lim_{n\rightarrow\infty}V_n = \lim_{n\rightarrow\infty} \bigcap_{k=1}^n V_n= \bigcap_{n=1}^\infty V_k,$$

which consists of the elements in $\Omega$ that appear in all $V\_k$. Thus, for increasing and decreasing sequences of sets, the limit can be defined in terms of unions and intersections.




Lastly, we combine these two intuitions. Consider the sequence $\\{X\_n\\}$, and let $\mathcal Y\_n$ be the tail sequence starting at $n$, i.e., $\mathcal Y\_n = \\{X\_n, X\_{n+1},...\\}$. The least upper bound of the tail sequence is $\sup\_{k\ge n} \mathcal Y\_n = \bigcup\_{k=n}^\infty X\_k$. Notice that $\\{\sup\_{k\ge n} \mathcal Y\_n\\}\_{n=1}^\infty$ is itself a sequence of sets, which is decreasing in $n$. That is,

$$\bigcup_{k=n}^\infty X_k   = \sup_{k\ge n} \mathcal Y_n \supseteq \sup_{k\ge n+1} \mathcal Y_{n+1} = \bigcup_{k=n+1}^\infty X_k.$$

But as we have just shown, for a decreasing sequence of sets, the limit is expressed in terms of intersections. Hence, we have

$$\lim_{n\rightarrow\infty}\left(\sup_{k\ge n} \mathcal Y_n\right) = \bigcap_{n=1}^\infty \sup_{k\ge n} \mathcal Y_n = \bigcap_{n=1}^\infty \left(\bigcup_{k = n}^\infty X_k\right) = \limsup_{n\rightarrow\infty} X_n.$$

We might interpret this as follows. Consider an element $\omega \in \bigcup\_{k=n}^\infty X\_k$. This element is a member of at least one set in the tail sequence $\\{X\_n, X\_{n+1},...\\}$. If $\omega\in \bigcap\_{n=1}^\infty \bigcup\_{k = n}^\infty X\_k$, we further require that this is true for all $n\ge 1$. In other words, we require $\omega$ to be an element of $X\_1\cup X\_2\cup \cdots$, $X\_2\cup X\_3\cup \cdots$, $X\_{n}\cup X\_{n+1} \cup \cdots $ and so on. No matter how far down the sequence we go, $\omega$ must be a member of *at least one* of the sets. But as there are infinitely many tail sequences, this implies that $\omega$ has to belong to infinitely many $X\_n$'s.


An important thing to notice here is that there are not only infinitely many tail sequences but that each tail sequence consists of infinitely many sets. As $\omega \in \limsup X\_n $ even if $\omega$ belongs to only one set of each tail sequence, this implies that there might be also an infinite number of sets to which $\omega$ does *not* belong.


Next, consider the limit inferior. The infimum of the tail sequence $\mathcal Y\_n$ is $\inf\_{k\ge n} \mathcal Y\_n = \bigcap\_{k=n}^\infty X\_n$. The sequence $\\{\inf\_{k\ge n} \mathcal Y\_n\\}\_{n=1}^\infty$ is an increasing sequence in $n$, as

$$ \bigcap_{k=n}^\infty X_n = \inf_{k\ge n} \mathcal Y_n\subseteq \inf_{k\ge n+1} \mathcal Y_{n+1} = \bigcap_{k=n+1}^\infty X_k.$$

Hence,

$$\lim_{n\rightarrow\infty} \left(\inf_{k\ge n} \mathcal Y_n\right) = \bigcup_{n=1}^\infty \inf_{k\ge n} \mathcal Y_n = \bigcup_{n=1}^\infty \left(\bigcap_{k=n}^\infty X_k\right) = \liminf_{n\rightarrow\infty} X_n.$$

Again, to get an intuitive understanding, fix $n$ for the moment. An element $\omega \in \bigcap\_{k=n}^\infty X\_k$ is a member of *all* $X\_n$ in the tail sequence $\mathcal Y\_n = \\{X\_n, X\_{n+1},...\\}$. There is only a finite number of sets up to $X\_n$, but there are infinitely many sets $X\_k$ with $k\ge n$; and $\omega$ has to belong to all of them. Thus $\omega$ has to be a member of *all but a finite number* of sets in the sequence $\\{X\_n\\}$. The set $\liminf X\_n$ consists of all $\omega \in \Omega$ that meet this condition.


Notice that an element in $\liminf X\_n$ has to be also an element of $\limsup X\_n$. Suppose that $\omega \in \liminf\_{n\rightarrow\infty} X\_n$. Then $\omega \in \bigcup\_{n=1}^\infty \bigcap\_{k=n}^\infty X\_k$, which implies that there exists a natural number $N$ such that for all $n\ge N$, $\omega$ is a member of $X\_n$. That is, from the $N$th term onwards in the sequence $\\{X\_n\\}$, $\omega$ is an element to all of the remaining sets, $\\{X\_{N}, X\_{N+1},...\\}$. Hence, $\omega$ must be an element of every tail sequence $\mathcal Y\_n$, $n\ge 1$ and, accordingly, a member of their intersection. Thus, $\omega \in \bigcap\_{n=1}^\infty \mathcal Y\_n = \bigcap\_{n=1}^\infty \bigcup\_{k=n}^\infty X\_k= \limsup\_{n\rightarrow\infty} X\_n.$ So, we have

$$\liminf_{n\rightarrow\infty} X_n \subseteq \limsup_{n\rightarrow\infty}X_n.$$

Intuitively, the same results can be also seen by the fact that if $\omega$ is a member of all but infinitely many $X\_n$ ($\liminf$), then it has to be a member of infinitely many $X\_n$ ($\limsup$).


Another result which can be shown using DeMorgan's Laws is

$$\begin{aligned}
\liminf_{n\rightarrow\infty}X_n^C &= \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty X_k^C = \bigcup_{n=1}^\infty \left(\bigcup_{k=n}^\infty X_k\right)^C = \left(\bigcap_{n=1}^\infty \bigcup_{k=n}^\infty X_k\right)^C \\
&= \left(\limsup_{n\rightarrow\infty} X_n\right)^C.
\end{aligned}$$

and similarly

$$\limsup_{n\rightarrow\infty} X_n^C = \left(\liminf_{n\rightarrow\infty} X_n\right)^C.$$



<h3> Continuity of Probability </h3>


It turns out that limit inferior and superior of sets is really important for understanding probability, as events are always represented by subsets of the sample space.


Consider the probability space $(\Omega, \mathcal F, P)$, where $\Omega$ is the sample space, $\mathcal F$ a sigma algebra of events and $P:\mathcal F \rightarrow [0,1]$ a probability measure. By continuity of probability, we roughly mean that the function $P$ preserves limiting processes. As we have considered sequences of sets above, let us think about how this idea can be applied to probabilities of sequences of events.


First, consider a pairwise disjoint sequence of sets, $\\{D\_n\\} \in \mathcal F$. By the countable additivity of probability measure, we have

$$P\left(\bigcup_{n=1}^\infty D_n\right) = \sum_{n=1}^\infty P(D_n).$$

Next, let $\\{A\_n\\}\in \mathcal F$ be an increasing sequence of events, where the meaning of increasing is with respect to set inclusion. Define $D\_1 = A\_1$ and $D\_n = A\_n\setminus A\_{n-1}$. As $\\{A\_n\\}$ is an increasing sequence, we have that $A\_{n-1} \subseteq A\_{n}$. So $D\_n$ is a set of those elements in $A\_n$ that are not in $A\_{n-1}$ or any set before $A\_{n-1}$ in the sequence. Thus, the sequence $\\{D\_n\\}$ consists of pairwise disjoint sets. Further $\bigcup\_{n=1}^\infty D\_n = \bigcup\_{n=1}^\infty A\_n$ by construction. Hence, by countable additivity of $P$, it follows that

$$P\left(\bigcup_{n=1}^\infty A_n\right) = P\left(\bigcup_{n=1}^\infty D_n\right) = \lim_{k\rightarrow\infty} \sum_{n=1}^k P(D_n).$$

But, as $D\_n  = A\_n \setminus A\_{n-1}$, we have $P(D\_n) = P(A\_n) - P(A\_{n-1})$ for all $n$. Hence, for a fixed $k$, $\sum\_{n=1}^k P(D\_n) = P(A\_k)$. It follows that $\lim\_{k\rightarrow\infty} \sum\_{n=1}^k P(D\_k) = \lim\_{k\rightarrow\infty} P(A\_k)$. Putting these together, we get

$$P\left( \lim_{n\rightarrow\infty} A_n\right) = P\left(\bigcup_{n=1}^\infty A_n\right) =\lim_{n\rightarrow\infty}\sum_{k=1}^n P(D_k) =  \lim_{n\rightarrow\infty} P(A_n)$$

for increasing sequences $\\{A\_n\\}$. Notice how the limit operator moves in and out of the probability function. Being able to do so is what we mean by continuity of probability.


For decreasing sequences of sets $\\{A\_n\\}$ we can use the following trick. If $A\subseteq B$, then $A^C \supseteq B^C$. Hence, if $\\{A\_n\\}$ is an decreasing sequence, then $\\{A\_n^C\\}$ is an increasing sequence. So,



$$\begin{aligned}
P\left(\lim_{n\rightarrow\infty} A_n\right) & = P\left(\bigcap_{n=1}^\infty A_n\right) = 1 - P\left(\bigcap_{n=1}^\infty A_n\right)^C = 1 - P\left(\bigcup_{n=1}^\infty A_n^C\right)  \\& = 1 - \lim_{n\rightarrow\infty} P(A_n^C) = \lim_{n\rightarrow\infty}[1 - P(A_n^C)] \\&= \lim_{n\rightarrow\infty}P( A_n).
\end{aligned}$$





Lastly, let $(A\_n)$ be an arbitrary sequence of events, not necessarily monotonic. We note that $\bigcup\_{k=1}^n A\_k$ is an increasing sequence in $n$. Hence,

$$P\left(\bigcup_{k=1}^\infty A_k\right) = P\left(\lim_{n\rightarrow\infty} \bigcup_{k=1}^n A_k\right) = \lim_{n\rightarrow\infty} P\left(\bigcup_{k=1}^n A_k\right).$$

Similarly, as $\bigcap\_{k=1}^n A\_k$ is decreasing in $n$, it follows that

$$P\left(\bigcap_{k=1}^\infty A_k\right) = P\left(\lim_{n\rightarrow\infty} \bigcap_{k=1}^n A_k\right) = \lim_{n\rightarrow\infty} P\left(\bigcap_{k=1}^n A_k\right).$$

Also, we have that

$$P\left(\limsup_{n\rightarrow\infty} A_n\right) = P\left(\bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k\right) = P\left(\lim_{n\rightarrow\infty} \bigcup_{k=n}^\infty A_k \right) = \lim_{n\rightarrow\infty}P\left(\bigcup_{k=n}^\infty A_k\right).$$

The first step is just the definition of limit superior. The second step follows from the fact that $Y\_n = \bigcup\_{k=n}^\infty A\_k$ is a decreasing sequence, such that $\bigcap\_{n=1}^\infty Y\_n = \lim\_{n\rightarrow\infty} Y\_n $, and the last step from the continuity of probability. Analogously, as $\bigcap\_{k=n} A\_k$ is a increasing sequence, we have

$$P\left(\liminf_{n\rightarrow\infty}A_n\right) = \lim_{n\rightarrow\infty}P\left(\bigcap_{k=n}^\infty A_k\right).$$



<h3> Borel-Cantelli Lemmas </h3>


Once we have understood limit inferior/superior of sequence of sets and the continuity property of probability measure, proving the Borel-Cantelli Lemmas is straightforward. So, here are the lemmas and their proof.



**Theorem**(*First Borel-Cantelli Lemma*) 
Let $(\Omega, \mathcal F, P)$ be a probability space. Suppose $\\{A\_n\\}\_{n=1}^\infty$ is a sequence of events. If $\sum\_{k=1}^\infty P(A\_k) < \infty$ then $P(\limsup\_{n\rightarrow\infty}A\_n) = 0$.
 



Again, we might ask, what is the meaning of this? To start from scratch, each element $\omega\in \Omega$ is an outcome from some random process. An event $A\_n$ is a collection of outcomes, and we say that event $A\_n$ has occurred if we observe an $\omega \in A\_n$ from the process. The probability of the event $A\_n$, $P(A\_n)$, is thus the probability that we observe an outcome $\omega$ that belongs to $A\_n$. Now, the set $\limsup A\_n$ is the set of $\omega \in \Omega$ that belong to infinitely many sets in the sequence $\\{A\_n\\}$. That is $\limsup\_n A\_n = \\{\omega \in \Omega: \omega \in A\_n \text{ for infinitely many } n\\}$. As a sigma-algebra is closed under countable unions and intersections, $\limsup\_n A\_n$ is an element of $\mathcal F$, and is, therefore, an event as well. If the event $\limsup\_n A\_n$ "occurs,'' which means that we observe some $\omega \in \limsup\_n A\_n$, then infinitely many events in $\\{A\_n\\}$ are occurring. Hence, $P(\limsup\_n A\_n)$ is the probability that infinitely many of the $A\_n$ in $\\{A\_n\\}$ occur. What the first Borel-Cantelli Lemma is saying is therefore the following: if the sum of the probabilities of events in the sequence $\\{A\_n\\}$ is finite (read "small'' or "not too large''), then the probability that infinitely many of the $A\_n$ occur must be zero, i.e., only finitely many of the $A\_n$ can occur with positive probability.


So, here is the proof of the lemma.



 *** 

$$P\left(\limsup_{n\rightarrow\infty} A_n\right) = P\left(\bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k\right) = P\left(\lim_{n\rightarrow\infty} \bigcup_{k=n}^\infty A_k \right) = \lim_{n\rightarrow\infty}P\left(\bigcup_{k=n}^\infty A_k\right).$$

By the countable subadditivity of $P$, we have

$$P\left(\bigcup_{k=n}^\infty A_k\right) \le \sum_{k=n}^\infty P(A_k) $$

for all $n$. But, by assumption,  $\sum_{k=1}^\infty P(A_k) < \infty$. Hence,

$$\lim_{n\rightarrow\infty} P\left(\bigcup_{k=n}^\infty A_k\right) \le \lim_{n\rightarrow\infty} \sum_{k=n}^\infty P(A_k) = \lim_{n\rightarrow\infty}\left[\sum_{k=1}^\infty P(A_k) - \sum_{k=1}^{n-1}P(A_k) \right] = 0.$$

<div style="text-align: right"> Q.E.D </div> 
 ***


Here's the second Borel-Cantelli Lemma:



**Theorem**(*Second Borel-Cantelli Lemma*) 
Let $\\{A\_n\\}\_{n=1}^\infty$ be a sequence of independent events. If $\sum\_{n=1}^\infty P(A\_n) = \infty$ then $P(\limsup\_{n\rightarrow\infty} A\_n) = 1$.
 



That is, if the sum of probabilities of a sequence of *independent* events is infinite, then the probability that infinite events from the sequence occur must be equal to one.



 *** 
Note that $1 - P(A_n) \le \exp[-P(A_n)]$ for all $n$ (see, Excursion on Gibbs Inequality section in this post). Further, we have

$$P\left[\left(\limsup_{n\rightarrow\infty}A_n\right)^C\right] = P\left(\liminf_{n\rightarrow\infty}A_n^C\right) = \lim_{n\rightarrow\infty}P\left(\bigcap_{k=n}^\infty A_k^C\right).$$

But by hypothesis the events are independent. It follows that

$$\begin{aligned}
P\left(\bigcap_{k=n}^\infty A_k^C\right) &= \prod_{k=n}^\infty P(A_k^C) = \prod_{k=n}^\infty[1-P(A_k)] \\ & \le \prod_{k=n}^\infty\exp\left[-P(A_k)\right]= \exp\left[-\sum_{k=n}^\infty P(A_k)\right] \\
&=\exp\left[-\left(\sum_{k=1}^\infty P(A_k) - \sum_{k=1}^{n-1}P(A_k)\right)\right] \\
&=0
\end{aligned}$$






as, by assumption, $\sum_{k=1}^\infty P(A_k) = \infty$. Hence,

$$P\left(\limsup_{n\rightarrow\infty}A_n\right) = 1 - P\left[\left(\limsup_{n\rightarrow\infty}A_n\right)^C\right] = 1.$$

<div style="text-align: right"> Q.E.D </div> 
 ***


A small note: the definition of independent events is that for any *finite* sub-collection $J$ of the events $\\{A\_n\\}$, the following holds: $P(\cap\_{n\in J}A\_n)= \prod\_{n\in J}P(A\_n)$. The generalization to an infinite collection of events follows from the continuity property of $P$.




<h3> So, What About the Monkeys? </h3>


The first Borel-Cantelli Lemma is often used in proving the Strong Law of Large Numbers. The Second Lemma is a direct proof of the Infinite Monkey Theorem, that was introduced at the start of the post.


Recall that the theorem says that if an infinite number of monkeys randomly punch on a typewriter, one of them will write Hamlet with probability one. We don't even need that they punch on the typewriter for an infinite amount of time, it is sufficient that they punch more than the number of characters in Hamlet.


To see the connection to the Borel-Cantelli Lemma, let $A\_n$ be the event that monkey $n$ writes Hamlet and let $k$ be the number of characters in the tragedy. Suppose that typewriter has $q$ keys. The probability of the event $A\_n$ is then equal to the probability of sampling a particular ordered set of size $k$ (that is the characters in Hamlet) from a pool of size $q$, were we are sampling with replacement. Hence, $P(A\_n) = q^{-k}$, which will be extremely small but still strictly positive. It follows that $\sum\_{n=1}^\infty P(A\_n) = \infty$, and by the second Borel-Cantelli Lemma, we have $P(\limsup\_{n\rightarrow\infty} A\_n) = 1$. So, we see that the conclusion is even stronger than the original statement: the probability that an *infinite* number of monkeys, not only one, will write Hamlet is equal to one.
